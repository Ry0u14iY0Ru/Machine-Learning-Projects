{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u9UlS_u-oNs"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzHzOJxodzEq",
        "outputId": "310351ce-0151-4835-fec5-44a4e22954d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.16.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "99hCRrVPeWvu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.impute import SimpleImputer\n",
        "from category_encoders import CountEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfpDzuX4-riK"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ThalorBb4s9",
        "outputId": "2598fdec-9a07-43ba-fa9a-4d059b751510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (24084, 34)\n",
            "Validation shape: (24084, 34)\n",
            "Test shape: (24815, 34)\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/dataS21/DontGetKicked/training.csv')\n",
        "\n",
        "data['PurchDate'] = pd.to_datetime(data['PurchDate'])\n",
        "\n",
        "data = data.sort_values('PurchDate')\n",
        "\n",
        "n = len(data)\n",
        "train_end = int(n * 0.33)\n",
        "valid_end = int(n * 0.66)\n",
        "\n",
        "train_data = data.iloc[:train_end].copy()\n",
        "valid_data = data.iloc[train_end:valid_end].copy()\n",
        "test_data = data.iloc[valid_end:].copy()\n",
        "\n",
        "print(f\"Train shape: {train_data.shape}\")\n",
        "print(f\"Validation shape: {valid_data.shape}\")\n",
        "print(f\"Test shape: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lxTFbOU4eXUZ"
      },
      "outputs": [],
      "source": [
        "numeric_cols = train_data.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = train_data.select_dtypes(include=['object']).columns\n",
        "\n",
        "target_col = 'IsBadBuy'\n",
        "numeric_cols = numeric_cols.drop(target_col, errors='ignore')\n",
        "categorical_cols = categorical_cols.drop(target_col, errors='ignore')\n",
        "\n",
        "numeric_imputer = SimpleImputer(strategy='median')\n",
        "train_data.loc[:, numeric_cols] = numeric_imputer.fit_transform(train_data[numeric_cols])\n",
        "valid_data.loc[:, numeric_cols] = numeric_imputer.transform(valid_data[numeric_cols])\n",
        "test_data.loc[:, numeric_cols] = numeric_imputer.transform(test_data[numeric_cols])\n",
        "\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "train_data.loc[:, categorical_cols] = categorical_imputer.fit_transform(train_data[categorical_cols])\n",
        "valid_data.loc[:, categorical_cols] = categorical_imputer.transform(valid_data[categorical_cols])\n",
        "test_data.loc[:, categorical_cols] = categorical_imputer.transform(test_data[categorical_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ooCmt2b7hDub"
      },
      "outputs": [],
      "source": [
        "for df in [train_data, valid_data, test_data]:\n",
        "    df.drop(columns=['PurchDate'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TlAphVFQecPQ"
      },
      "outputs": [],
      "source": [
        "count_enc = CountEncoder()\n",
        "count_enc.fit(train_data[categorical_cols])\n",
        "\n",
        "train_data.loc[:, categorical_cols] = count_enc.transform(train_data[categorical_cols])\n",
        "valid_data.loc[:, categorical_cols] = count_enc.transform(valid_data[categorical_cols])\n",
        "test_data.loc[:, categorical_cols] = count_enc.transform(test_data[categorical_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Hc5FDa0lguJM"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = train_data.drop(columns=['IsBadBuy']).values, train_data['IsBadBuy'].values\n",
        "X_valid, y_valid = valid_data.drop(columns=['IsBadBuy']).values, valid_data['IsBadBuy'].values\n",
        "X_test, y_test = test_data.drop(columns=['IsBadBuy']).values, test_data['IsBadBuy'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vnA0VEDgkUAw"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.astype(float)\n",
        "X_valid = X_valid.astype(float)\n",
        "X_test = X_test.astype(float)\n",
        "y_train = y_train.astype(int)\n",
        "y_valid = y_valid.astype(int)\n",
        "y_test = y_test.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z4KOXtF5gPi3"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV4tSvcs_Cat"
      },
      "source": [
        "# CustomMLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PXAdpQwjgGvE"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "    def __init__(self, n_hidden=100, activation='tanh', learning_rate=0.01, epochs=50,\n",
        "                 batch_size=32, optimizer='adam', random_seed=42):\n",
        "        \"\"\"Initialize MLP with one hidden layer.\n",
        "\n",
        "        Args:\n",
        "            n_hidden (int): Number of neurons in the hidden layer.\n",
        "            activation (str): Activation function for the hidden layer ('tanh', 'sigmoid', 'relu', 'cos').\n",
        "            learning_rate (float): Learning rate.\n",
        "            epochs (int): Number of epochs.\n",
        "            batch_size (int): Batch size.\n",
        "            optimizer (str): Optimizer ('sgd' or 'adam').\n",
        "            random_seed (int): Seed for random number generator.\n",
        "        \"\"\"\n",
        "        self.n_hidden = n_hidden\n",
        "        self.activation = activation\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.random_seed = random_seed\n",
        "        self.W1 = None\n",
        "        self.b1 = None\n",
        "        self.W2 = None\n",
        "        self.b2 = None\n",
        "\n",
        "    def _initialize_weights(self, n_features):\n",
        "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
        "        np.random.seed(self.random_seed)\n",
        "        self.W1 = np.random.randn(n_features, self.n_hidden) * 0.01\n",
        "        self.b1 = np.zeros((1, self.n_hidden))\n",
        "        self.W2 = np.random.randn(self.n_hidden, 2) * 0.01\n",
        "        self.b2 = np.zeros((1, 2))\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        \"\"\"Sigmoid activation function.\"\"\"\n",
        "        x = np.array(x, dtype=np.float64)\n",
        "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "    def _activation(self, z):\n",
        "        \"\"\"Activation function for the hidden layer.\"\"\"\n",
        "        z = np.array(z, dtype=np.float64)\n",
        "        if self.activation == 'tanh':\n",
        "            return np.tanh(z)\n",
        "        elif self.activation == 'sigmoid':\n",
        "            return self._sigmoid(z)\n",
        "        elif self.activation == 'relu':\n",
        "            return np.maximum(0, z)\n",
        "        elif self.activation == 'cos':\n",
        "            return np.cos(z)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown activation: choose 'tanh', 'sigmoid', 'relu', or 'cos'\")\n",
        "\n",
        "    def _activation_derivative(self, z, a):\n",
        "        \"\"\"The derivative of the activation function for the hidden layer.\"\"\"\n",
        "        z = np.array(z, dtype=np.float64)\n",
        "        if self.activation == 'tanh':\n",
        "            return 1 - a ** 2\n",
        "        elif self.activation == 'sigmoid':\n",
        "            return a * (1 - a)\n",
        "        elif self.activation == 'relu':\n",
        "            return np.where(z > 0, 1, 0)\n",
        "        elif self.activation == 'cos':\n",
        "            return -np.sin(z)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown activation: choose 'tanh', 'sigmoid', 'relu', or 'cos'\")\n",
        "\n",
        "    def _forward_pass(self, X):\n",
        "        \"\"\"Direct distribution.\"\"\"\n",
        "        X = np.array(X, dtype=np.float64)\n",
        "        z1 = np.dot(X, self.W1) + self.b1\n",
        "        a1 = self._activation(z1)\n",
        "        z2 = np.dot(a1, self.W2) + self.b2\n",
        "        a2 = self._sigmoid(z2)\n",
        "        return z1, a1, z2, a2\n",
        "\n",
        "    def _compute_loss(self, y_true, y_pred):\n",
        "        \"\"\"Calculating binary cross entropy.\"\"\"\n",
        "        y_true = np.array(y_true, dtype=int)\n",
        "        batch_size = y_true.shape[0]\n",
        "        y_true_one_hot = np.zeros((batch_size, 2))\n",
        "        y_true_one_hot[np.arange(batch_size), y_true] = 1\n",
        "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "        loss = -np.mean(y_true_one_hot * np.log(y_pred) + (1 - y_true_one_hot) * np.log(1 - y_pred))\n",
        "        return loss\n",
        "\n",
        "    def _backward_pass(self, X, y, z1, a1, z2, a2):\n",
        "        \"\"\"Backpropagation for computing gradients.\"\"\"\n",
        "        batch_size = X.shape[0]\n",
        "        y_one_hot = np.zeros((batch_size, 2))\n",
        "        y_one_hot[np.arange(batch_size), y] = 1\n",
        "\n",
        "        dz2 = a2 - y_one_hot\n",
        "        dW2 = np.dot(a1.T, dz2) / batch_size\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True) / batch_size\n",
        "\n",
        "        da1 = np.dot(dz2, self.W2.T)\n",
        "        dz1 = da1 * self._activation_derivative(z1, a1)\n",
        "\n",
        "        dW1 = np.dot(X.T, dz1) / batch_size\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True) / batch_size\n",
        "\n",
        "        return dW1, db1, dW2, db2\n",
        "\n",
        "    def fit(self, X_train, y_train, X_valid=None, y_valid=None):\n",
        "        \"\"\"Training a model using SGD or Adam.\"\"\"\n",
        "        X_train = np.array(X_train, dtype=np.float64)\n",
        "        y_train = np.array(y_train, dtype=int)\n",
        "        if X_valid is not None:\n",
        "            X_valid = np.array(X_valid, dtype=np.float64)\n",
        "            y_valid = np.array(y_valid, dtype=int)\n",
        "\n",
        "        n_samples, n_features = X_train.shape\n",
        "        self._initialize_weights(n_features)\n",
        "\n",
        "        if self.optimizer == 'adam':\n",
        "            m_W1, v_W1 = np.zeros_like(self.W1), np.zeros_like(self.W1)\n",
        "            m_b1, v_b1 = np.zeros_like(self.b1), np.zeros_like(self.b1)\n",
        "            m_W2, v_W2 = np.zeros_like(self.W2), np.zeros_like(self.W2)\n",
        "            m_b2, v_b2 = np.zeros_like(self.b2), np.zeros_like(self.b2)\n",
        "            beta1, beta2, epsilon = 0.9, 0.999, 1e-8\n",
        "            t = 0\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            indices = np.random.permutation(n_samples)\n",
        "            X_train_shuffled = X_train[indices]\n",
        "            y_train_shuffled = y_train[indices]\n",
        "\n",
        "            for i in range(0, n_samples, self.batch_size):\n",
        "                X_batch = X_train_shuffled[i:i + self.batch_size]\n",
        "                y_batch = y_train_shuffled[i:i + self.batch_size]\n",
        "                z1, a1, z2, a2 = self._forward_pass(X_batch)\n",
        "                dW1, db1, dW2, db2 = self._backward_pass(X_batch, y_batch, z1, a1, z2, a2)\n",
        "\n",
        "                if self.optimizer == 'sgd':\n",
        "                    self.W1 -= self.learning_rate * dW1\n",
        "                    self.b1 -= self.learning_rate * db1\n",
        "                    self.W2 -= self.learning_rate * dW2\n",
        "                    self.b2 -= self.learning_rate * db2\n",
        "                elif self.optimizer == 'adam':\n",
        "                    t += 1\n",
        "                    m_W1 = beta1 * m_W1 + (1 - beta1) * dW1\n",
        "                    v_W1 = beta2 * v_W1 + (1 - beta2) * (dW1 ** 2)\n",
        "                    m_W1_hat = m_W1 / (1 - beta1 ** t)\n",
        "                    v_W1_hat = v_W1 / (1 - beta2 ** t)\n",
        "                    self.W1 -= self.learning_rate * m_W1_hat / (np.sqrt(v_W1_hat) + epsilon)\n",
        "                    m_b1 = beta1 * m_b1 + (1 - beta1) * db1\n",
        "                    v_b1 = beta2 * v_b1 + (1 - beta2) * (db1 ** 2)\n",
        "                    m_b1_hat = m_b1 / (1 - beta1 ** t)\n",
        "                    v_b1_hat = v_b1 / (1 - beta2 ** t)\n",
        "                    self.b1 -= self.learning_rate * m_b1_hat / (np.sqrt(v_b1_hat) + epsilon)\n",
        "                    m_W2 = beta1 * m_W2 + (1 - beta1) * dW2\n",
        "                    v_W2 = beta2 * v_W2 + (1 - beta2) * (dW2 ** 2)\n",
        "                    m_W2_hat = m_W2 / (1 - beta1 ** t)\n",
        "                    v_W2_hat = v_W2 / (1 - beta2 ** t)\n",
        "                    self.W2 -= self.learning_rate * m_W2_hat / (np.sqrt(v_W2_hat) + epsilon)\n",
        "                    m_b2 = beta1 * m_b2 + (1 - beta1) * db2\n",
        "                    v_b2 = beta2 * v_b2 + (1 - beta2) * (db2 ** 2)\n",
        "                    m_b2_hat = m_b2 / (1 - beta1 ** t)\n",
        "                    v_b2_hat = v_b2 / (1 - beta2 ** t)\n",
        "                    self.b2 -= self.learning_rate * m_b2_hat / (np.sqrt(v_b2_hat) + epsilon)\n",
        "\n",
        "            _, _, _, train_pred = self._forward_pass(X_train)\n",
        "            train_loss = self._compute_loss(y_train, train_pred)\n",
        "\n",
        "            if X_valid is not None and y_valid is not None:\n",
        "                _, _, _, valid_pred = self._forward_pass(X_valid)\n",
        "                valid_loss = self._compute_loss(y_valid, valid_pred)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predicting class probabilities.\"\"\"\n",
        "        X = np.array(X, dtype=np.float64)\n",
        "        _, _, _, a2 = self._forward_pass(X)\n",
        "        return a2\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predicting class labels.\"\"\"\n",
        "        proba = self.predict_proba(X)\n",
        "        return np.argmax(proba, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5mKOCtYWkXiQ"
      },
      "outputs": [],
      "source": [
        "def gini_score(y_true, y_pred_proba):\n",
        "    \"\"\"Calculating the Gini coefficient based on ROC-AUC.\"\"\"\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
        "    return 2 * roc_auc - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pxDMJ8bhyJPl"
      },
      "outputs": [],
      "source": [
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vocmuIjrgMoq"
      },
      "outputs": [],
      "source": [
        "activations = ['tanh', 'sigmoid', 'relu']\n",
        "optimizers = ['adam', 'sgd']\n",
        "\n",
        "for activation in activations:\n",
        "    for optimizer in optimizers:\n",
        "        model = MLP(\n",
        "            n_hidden=128,\n",
        "            activation=activation,\n",
        "            learning_rate=0.01 if optimizer == 'adam' else 0.001,\n",
        "            epochs=16,\n",
        "            batch_size=64,\n",
        "            optimizer=optimizer\n",
        "        )\n",
        "        model.fit(X_train, y_train, X_valid, y_valid)\n",
        "\n",
        "        proba_valid = model.predict_proba(X_valid)\n",
        "        predictions_valid = model.predict(X_valid)\n",
        "        roc_auc_valid = roc_auc_score(y_valid, proba_valid[:, 1])\n",
        "        gini_valid = gini_score(y_valid, proba_valid)\n",
        "        valid_accuracy = accuracy_score(y_valid, predictions_valid)\n",
        "\n",
        "        results.append({\n",
        "            'Model': 'CustomMLP',\n",
        "            'Activation': activation,\n",
        "            'Optimizer': optimizer,\n",
        "            'Validation Accuracy': valid_accuracy,\n",
        "            'Validation ROC-AUC': roc_auc_valid,\n",
        "            'Validation Gini': gini_valid,\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo88BjCc_J3P"
      },
      "source": [
        "# MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YVIgXMbPxinS"
      },
      "outputs": [],
      "source": [
        "def gini_score(y_true, y_pred_proba):\n",
        "    \"\"\"Calculating the Gini coefficient based on ROC-AUC.\"\"\"\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    return 2 * roc_auc - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3d1ABvzawH_V"
      },
      "outputs": [],
      "source": [
        "activations = ['tanh', 'logistic', 'relu']\n",
        "solvers = ['adam', 'sgd']\n",
        "\n",
        "for activation in activations:\n",
        "    for solver in solvers:\n",
        "        model = MLPClassifier(\n",
        "            hidden_layer_sizes=(128,),\n",
        "            activation=activation,\n",
        "            solver=solver,\n",
        "            learning_rate_init=0.001 if solver == 'adam' else 0.01,\n",
        "            max_iter=200 if solver == 'adam' else 500,\n",
        "            batch_size=64,\n",
        "            random_state=42,\n",
        "            early_stopping=True,\n",
        "            validation_fraction=0.1,\n",
        "            n_iter_no_change=20\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        proba_valid = model.predict_proba(X_valid)[:, 1]\n",
        "        predictions_valid = model.predict(X_valid)\n",
        "        roc_auc_valid = roc_auc_score(y_valid, proba_valid)\n",
        "        gini_valid = gini_score(y_valid, proba_valid)\n",
        "        valid_accuracy = accuracy_score(y_valid, predictions_valid)\n",
        "\n",
        "        results.append({\n",
        "            'Model': 'MLPClassifier',\n",
        "            'Activation': activation,\n",
        "            'Optimizer': solver,\n",
        "            'Validation Accuracy': valid_accuracy,\n",
        "            'Validation ROC-AUC': roc_auc_valid,\n",
        "            'Validation Gini': gini_valid,\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ygzdxct_N7J"
      },
      "source": [
        "# PyTorchMLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0BBqVPDwy8VZ"
      },
      "outputs": [],
      "source": [
        "class PyTorchMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=100, activation='tanh', learning_rate=0.001,\n",
        "                 epochs=200, batch_size=128, optimizer='adam', random_seed=42):\n",
        "        super(PyTorchMLP, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.activation = activation\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer_name = optimizer\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        if activation == 'tanh':\n",
        "            self.activation_fn = nn.Tanh()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation_fn = nn.Sigmoid()\n",
        "        elif activation == 'relu':\n",
        "            self.activation_fn = nn.ReLU()\n",
        "        else:\n",
        "            raise ValueError(\"Unknown activation: choose 'tanh', 'sigmoid', or 'relu'\")\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        torch.manual_seed(random_seed)\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.zeros_(self.fc1.bias)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.zeros_(self.fc2.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation_fn(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "    def _prepare_data(self, X, y=None):\n",
        "        \"\"\"Converting data into PyTorch tensors.\"\"\"\n",
        "        X = np.array(X, dtype=np.float64)\n",
        "        if y is not None:\n",
        "            y = np.array(y, dtype=np.int64).reshape(-1, 1)\n",
        "\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "        if y is not None:\n",
        "            y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "            return X_tensor, y_tensor\n",
        "        return X_tensor\n",
        "\n",
        "    def fit(self, X_train, y_train, X_valid=None, y_valid=None):\n",
        "        \"\"\"Training the model.\"\"\"\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.to(device)\n",
        "\n",
        "        X_train_tensor, y_train_tensor = self._prepare_data(X_train, y_train)\n",
        "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        if X_valid is not None and y_valid is not None:\n",
        "            X_valid_tensor, y_valid_tensor = self._prepare_data(X_valid, y_valid)\n",
        "        else:\n",
        "            X_valid_tensor, y_valid_tensor = None, None\n",
        "\n",
        "        if self.optimizer_name == 'adam':\n",
        "            optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        elif self.optimizer_name == 'sgd':\n",
        "            optimizer = optim.SGD(self.parameters(), lr=self.learning_rate, momentum=0.9)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown optimizer: choose 'adam' or 'sgd'\")\n",
        "\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            self.train()\n",
        "            train_loss = 0\n",
        "            for X_batch, y_batch in train_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item() * X_batch.size(0)\n",
        "            train_loss /= len(train_loader.dataset)\n",
        "\n",
        "            if X_valid_tensor is not None and y_valid_tensor is not None:\n",
        "                self.eval()\n",
        "                with torch.no_grad():\n",
        "                    outputs_valid = self(X_valid_tensor.to(device))\n",
        "                    valid_loss = criterion(outputs_valid, y_valid_tensor.to(device)).item()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predicting Probabilities.\"\"\"\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.eval()\n",
        "        X_tensor = self._prepare_data(X)\n",
        "        with torch.no_grad():\n",
        "            proba = self(X_tensor.to(device)).cpu().numpy().flatten()\n",
        "        return np.vstack([1 - proba, proba]).T\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predicting class labels.\"\"\"\n",
        "        proba = self.predict_proba(X)\n",
        "        return (proba[:, 1] > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZJibgtUj0I0o"
      },
      "outputs": [],
      "source": [
        "activations = ['tanh', 'sigmoid', 'relu']\n",
        "optimizers = ['adam', 'sgd']\n",
        "\n",
        "for activation in activations:\n",
        "    for opt in optimizers:\n",
        "        model = PyTorchMLP(\n",
        "            input_size=X_train.shape[1],\n",
        "            hidden_size=128,\n",
        "            activation=activation,\n",
        "            learning_rate=0.001 if opt == 'adam' else 0.01,\n",
        "            epochs=16,\n",
        "            batch_size=64,\n",
        "            optimizer=opt\n",
        "        )\n",
        "        model.fit(X_train, y_train, X_valid, y_valid)\n",
        "\n",
        "        proba_valid = model.predict_proba(X_valid)[:, 1]\n",
        "        predictions_valid = model.predict(X_valid)\n",
        "        roc_auc_valid = roc_auc_score(y_valid, proba_valid)\n",
        "        gini_valid = gini_score(y_valid, proba_valid)\n",
        "        valid_accuracy = accuracy_score(y_valid, predictions_valid)\n",
        "\n",
        "        results.append({\n",
        "            'Model': 'PyTorchMLP',\n",
        "            'Activation': activation,\n",
        "            'Optimizer': opt,\n",
        "            'Validation Accuracy': valid_accuracy,\n",
        "            'Validation ROC-AUC': roc_auc_valid,\n",
        "            'Validation Gini': gini_valid,\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvvKYMC3ATSl"
      },
      "source": [
        "PyTorchMLP is expected to perform better due to:\n",
        "\n",
        "1. Automatic gradient computation via Autograd\n",
        "2. Efficient batch processing via DataLoader\n",
        "3. Numerical stability due to PyTorch's built-in mechanisms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5FlrYj5_R-Q"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "D88EsmZo3Sbx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "5520cd12-73ab-4751-f6d6-9b9daed16b3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Model Activation Optimizer  Validation Accuracy  \\\n",
              "0       CustomMLP       tanh      adam             0.868626   \n",
              "1       CustomMLP       tanh       sgd             0.868876   \n",
              "2       CustomMLP    sigmoid      adam             0.869042   \n",
              "3       CustomMLP    sigmoid       sgd             0.868876   \n",
              "4       CustomMLP       relu      adam             0.868460   \n",
              "5       CustomMLP       relu       sgd             0.868876   \n",
              "6   MLPClassifier       tanh      adam             0.869249   \n",
              "7   MLPClassifier       tanh       sgd             0.869042   \n",
              "8   MLPClassifier   logistic      adam             0.868834   \n",
              "9   MLPClassifier   logistic       sgd             0.868876   \n",
              "10  MLPClassifier       relu      adam             0.869665   \n",
              "11  MLPClassifier       relu       sgd             0.869540   \n",
              "12     PyTorchMLP       tanh      adam             0.868917   \n",
              "13     PyTorchMLP       tanh       sgd             0.868959   \n",
              "14     PyTorchMLP    sigmoid      adam             0.868917   \n",
              "15     PyTorchMLP    sigmoid       sgd             0.869000   \n",
              "16     PyTorchMLP       relu      adam             0.869125   \n",
              "17     PyTorchMLP       relu       sgd             0.868959   \n",
              "\n",
              "    Validation ROC-AUC  Validation Gini  \n",
              "0             0.666855         0.333710  \n",
              "1             0.643507         0.287014  \n",
              "2             0.674960         0.349919  \n",
              "3             0.634730         0.269459  \n",
              "4             0.679959         0.359919  \n",
              "5             0.620606         0.241213  \n",
              "6             0.685451         0.370903  \n",
              "7             0.670666         0.341331  \n",
              "8             0.658606         0.317213  \n",
              "9             0.650164         0.300328  \n",
              "10            0.671269         0.342539  \n",
              "11            0.668996         0.337992  \n",
              "12            0.687585         0.375169  \n",
              "13            0.682375         0.364749  \n",
              "14            0.673533         0.347066  \n",
              "15            0.666597         0.333193  \n",
              "16            0.682626         0.365252  \n",
              "17            0.684117         0.368233  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf0473bb-5577-4f2a-8d47-1f90ed402ffa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Activation</th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "      <th>Validation ROC-AUC</th>\n",
              "      <th>Validation Gini</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CustomMLP</td>\n",
              "      <td>tanh</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.868626</td>\n",
              "      <td>0.666855</td>\n",
              "      <td>0.333710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CustomMLP</td>\n",
              "      <td>tanh</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.868876</td>\n",
              "      <td>0.643507</td>\n",
              "      <td>0.287014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CustomMLP</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.869042</td>\n",
              "      <td>0.674960</td>\n",
              "      <td>0.349919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CustomMLP</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.868876</td>\n",
              "      <td>0.634730</td>\n",
              "      <td>0.269459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CustomMLP</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.868460</td>\n",
              "      <td>0.679959</td>\n",
              "      <td>0.359919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CustomMLP</td>\n",
              "      <td>relu</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.868876</td>\n",
              "      <td>0.620606</td>\n",
              "      <td>0.241213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>tanh</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.869249</td>\n",
              "      <td>0.685451</td>\n",
              "      <td>0.370903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>tanh</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.869042</td>\n",
              "      <td>0.670666</td>\n",
              "      <td>0.341331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>logistic</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.868834</td>\n",
              "      <td>0.658606</td>\n",
              "      <td>0.317213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>logistic</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.868876</td>\n",
              "      <td>0.650164</td>\n",
              "      <td>0.300328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.869665</td>\n",
              "      <td>0.671269</td>\n",
              "      <td>0.342539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>relu</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.869540</td>\n",
              "      <td>0.668996</td>\n",
              "      <td>0.337992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PyTorchMLP</td>\n",
              "      <td>tanh</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.868917</td>\n",
              "      <td>0.687585</td>\n",
              "      <td>0.375169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PyTorchMLP</td>\n",
              "      <td>tanh</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.868959</td>\n",
              "      <td>0.682375</td>\n",
              "      <td>0.364749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PyTorchMLP</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.868917</td>\n",
              "      <td>0.673533</td>\n",
              "      <td>0.347066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>PyTorchMLP</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.869000</td>\n",
              "      <td>0.666597</td>\n",
              "      <td>0.333193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>PyTorchMLP</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.869125</td>\n",
              "      <td>0.682626</td>\n",
              "      <td>0.365252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>PyTorchMLP</td>\n",
              "      <td>relu</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.868959</td>\n",
              "      <td>0.684117</td>\n",
              "      <td>0.368233</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf0473bb-5577-4f2a-8d47-1f90ed402ffa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf0473bb-5577-4f2a-8d47-1f90ed402ffa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf0473bb-5577-4f2a-8d47-1f90ed402ffa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-75e301fb-d570-4141-9b88-56f3bdf3fd87\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75e301fb-d570-4141-9b88-56f3bdf3fd87')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-75e301fb-d570-4141-9b88-56f3bdf3fd87 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4842608e-a9a6-499f-8737-33ecb52d9585\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4842608e-a9a6-499f-8737-33ecb52d9585 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"CustomMLP\",\n          \"MLPClassifier\",\n          \"PyTorchMLP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"sigmoid\",\n          \"logistic\",\n          \"tanh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"sgd\",\n          \"adam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002818114365291274,\n        \"min\": 0.8684603886397608,\n        \"max\": 0.8696645075568843,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.8690001660853679,\n          0.8689586447433981\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation ROC-AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01870269484250621,\n        \"min\": 0.6206063321416637,\n        \"max\": 0.68758452460454,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.6668549514054077,\n          0.6435068518838089\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation Gini\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03740538968501242,\n        \"min\": 0.24121266428332744,\n        \"max\": 0.37516904920908,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.3337099028108155,\n          0.2870137037676177\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yttpAU_v5eTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fde605-3d1f-4b26-a0b9-7ac748f0c7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Gini: 0.4931\n",
            "Validation Gini: 0.3653\n",
            "Test Gini: 0.4209\n"
          ]
        }
      ],
      "source": [
        "model = PyTorchMLP(\n",
        "    input_size=X_train.shape[1],\n",
        "    hidden_size=128,\n",
        "    activation='relu',\n",
        "    learning_rate=0.001,\n",
        "    epochs=16,\n",
        "    batch_size=64,\n",
        "    optimizer='adam'\n",
        ")\n",
        "model.fit(X_train, y_train, X_valid, y_valid)\n",
        "\n",
        "proba_train = model.predict_proba(X_train)[:, 1]\n",
        "gini_train = gini_score(y_train, proba_train)\n",
        "print(f\"Training Gini: {gini_train:.4f}\")\n",
        "\n",
        "proba_valid = model.predict_proba(X_valid)[:, 1]\n",
        "gini_valid = gini_score(y_valid, proba_valid)\n",
        "print(f\"Validation Gini: {gini_valid:.4f}\")\n",
        "\n",
        "proba_test = model.predict_proba(X_test)[:, 1]\n",
        "gini_test = gini_score(y_test, proba_test)\n",
        "print(f\"Test Gini: {gini_test:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are dips in the metric on the validation dataset, but on the test dataset it increases again, which indicates the absence of overfitting."
      ],
      "metadata": {
        "id": "AQyWDBUqCmKg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_u9UlS_u-oNs",
        "dfpDzuX4-riK",
        "bV4tSvcs_Cat",
        "Fo88BjCc_J3P",
        "0Ygzdxct_N7J",
        "e5FlrYj5_R-Q"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}